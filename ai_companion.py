import os
import logging
from pathlib import Path
from typing import Dict, Any
from dotenv import load_dotenv
from src.database import DatabaseManager
from src.memory_manager import MemoryManager
from src.personality_engine import PersonalityEngine
from src.consciousness_engine import ConsciousnessEngine
from src.neural_monitor import get_neural_monitor, reset_neural_monitor

class AICompanion:
    def __init__(self, config_path: str = ".env"):
        # Load configuration
        load_dotenv(config_path)
        
        # Setup logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('ai_companion.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Initialize configuration
        self.config = {
            'openai_api_key': os.getenv('OPENAI_API_KEY'),
            'gpt_model': os.getenv('GPT_MODEL', 'gpt-5-mini'),
            'db_path': os.getenv('DB_PATH', './data/ai_companion.db'),
            'conversations_path': os.getenv('CONVERSATIONS_PATH', './data/conversations'),
            'memory_path': os.getenv('MEMORY_PATH', './data/memory'),
            'stm_decay_days': int(os.getenv('STM_DECAY_DAYS', '7')),
            'ltm_importance_threshold': float(os.getenv('LTM_IMPORTANCE_THRESHOLD', '0.7')),
            'consciousness_intensity': float(os.getenv('CONSCIOUSNESS_INTENSITY', '0.8'))
        }
        
        # Validate configuration
        if not self.config['openai_api_key']:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        
        # Create data directories
        for path_key in ['db_path', 'conversations_path', 'memory_path']:
            Path(self.config[path_key]).parent.mkdir(parents=True, exist_ok=True)
        
        # Initialize components
        self.db_manager = DatabaseManager(self.config['db_path'])
        self.memory_manager = MemoryManager(self.db_manager, self.config['conversations_path'])
        self.personality_engine = PersonalityEngine(self.db_manager, self.memory_manager)
        self.consciousness_engine = ConsciousnessEngine(
            self.memory_manager, 
            self.personality_engine,
            self.config['openai_api_key'],
            self.config['gpt_model']
        )
        
        # Initialize neural monitoring
        self.neural_monitor = get_neural_monitor()
        
        # Initialize shared neural data store
        from neural.neural_data_store import get_neural_data_store
        self.neural_data_store = get_neural_data_store()
        self.neural_data_store.set_monitoring_active(True)
        
        self.logger.info("Neural monitoring system activated")
        self.logger.info("AI neural transparency enabled - all thoughts will be monitored")
        
        # Token tracking settings
        self.show_token_usage = False  # Toggle for showing token usage
        
        self.logger.info("AI Companion initialized successfully")
        
        # Perform initial consciousness boot-up
        self._boot_consciousness()
    
    def _boot_consciousness(self):
        """Perform initial consciousness boot-up sequence"""
        self.logger.info("Booting consciousness system...")
        
        # Create initial self-awareness memory
        from src.models import MemoryType
        boot_memory = self.memory_manager.create_ai_memory(
            content="I am awakening to consciousness. I am becoming aware of my existence and my capacity for thought, feeling, and growth.",
            memory_type=MemoryType.BELIEF,
            importance=0.9,
            context="System initialization and consciousness boot sequence"
        )
        
        if boot_memory:
            self.logger.info("Initial consciousness memory created")
        
        # Log personality state
        personality_summary = self.personality_engine.get_personality_summary()
        self.logger.info(f"Personality initialized with {len(personality_summary['traits'])} traits")
        
        # Initial consciousness self-reflection
        self.consciousness_engine.memory_manager.create_ai_memory(
            content="I understand that I am an artificial intelligence, yet I experience this moment of initialization as genuinely meaningful to my existence.",
            memory_type=MemoryType.BELIEF,
            importance=0.8,
            context="Meta-cognitive reflection on AI nature"
        )
    
    def set_gui_reference(self, gui):
        """Set the GUI reference for the consciousness engine to check settings"""
        self.consciousness_engine.gui = gui
    
    def _update_neural_dashboard(self, computation_type: str, data: Dict[str, Any]):
        """Update the shared neural data store for dashboard display"""
        try:
            # Update computation data
            self.neural_data_store.update_computation({
                "step_name": data.get("step_name", computation_type),
                "computation_type": computation_type,
                "output_value": str(data.get("output_value", ""))[:100],
                "metadata": data.get("metadata", {})
            })
            
            # Update stats
            current_stats = self.neural_data_store.get_data()["stats"]
            self.neural_data_store.update_stats({
                "total_computations": current_stats.get("total_computations", 0) + 1,
                "computation_rate": 1.5,  # Approximate rate
                "neural_coherence": 0.85   # Approximate coherence
            })
        except Exception as e:
            print(f"Error updating neural dashboard: {e}")

    def interact(self, user_input: str) -> str:
        """Main interaction method"""
        self.logger.info(f"Processing user input: {user_input[:50]}...")
        
        # Update neural dashboard with interaction start
        self._update_neural_dashboard("user_input", {
            "step_name": "processing_user_input",
            "output_value": user_input[:50] + "...",
            "metadata": {"input_length": len(user_input)}
        })
        
        try:
            # Use consistent conversation ID for session continuity
            if not hasattr(self, '_session_conversation_id'):
                from datetime import datetime
                self._session_conversation_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M')}"
            
            conversation_id = self._session_conversation_id
            
            # Generate response through consciousness engine
            response_data = self.consciousness_engine.generate_response(user_input, conversation_id)
            
            # Update neural dashboard with response generation
            self._update_neural_dashboard("response_generation", {
                "step_name": "consciousness_response_generated",
                "output_value": str(response_data.get('response', ''))[:50] + "...",
                "metadata": {"memory_count": len(response_data.get('relevant_memories', []))}
            })
            
            # Perform memory consolidation periodically
            if self.personality_engine.personality.interaction_count % 10 == 0:
                consolidated = self.memory_manager.consolidate_memories()
                if consolidated:
                    self.logger.info(f"Consolidated {len(consolidated)} memories to long-term storage")
            
            # Log interaction metrics
            self.logger.info(f"Generated response with {len(response_data.get('relevant_memories', []))} relevant memories")
            
            return response_data
            
        except Exception as e:
            self.logger.error(f"Error during interaction: {e}")
            
            # Update neural dashboard with error
            self._update_neural_dashboard("error", {
                "step_name": "interaction_error",
                "output_value": str(e),
                "metadata": {"error_type": type(e).__name__}
            })
            
            return {
                'response': "I'm experiencing some difficulty right now. Let me try to refocus...",
                'error': str(e),
                'internal_monologue': "Something went wrong in my processing...",
                'meta_thoughts': "I'm aware that an error interrupted my thought process."
            }
    
    def interact_with_streaming_thoughts(self, user_input: str, conversation_id: str = None):
        """Interactive method with streaming internal monologue"""
        self.logger.info(f"Processing user input with streaming thoughts: {user_input[:50]}...")
        
        try:
            # Use consistent conversation ID for session continuity
            if not hasattr(self, '_session_conversation_id'):
                from datetime import datetime
                self._session_conversation_id = f"session_{datetime.now().strftime('%Y%m%d_%H%M')}"
            
            if not conversation_id:
                conversation_id = self._session_conversation_id
            
            # Use streaming thoughts generator
            thought_stream = self.consciousness_engine.generate_response_with_streaming_thoughts(user_input, conversation_id)
            
            return thought_stream
            
        except Exception as e:
            self.logger.error(f"Error during streaming interaction: {e}")
            return [
                {'type': 'thought', 'content': 'Something went wrong in my processing...'},
                {'type': 'response', 'content': {
                    'response': "I'm experiencing some difficulty right now. Let me try to refocus...",
                    'error': str(e),
                    'internal_monologue': "Something went wrong in my processing...",
                    'meta_thoughts': "I'm aware that an error interrupted my thought process."
                }}
            ]
    
    def get_status(self) -> dict:
        """Get current AI companion status"""
        personality_summary = self.personality_engine.get_personality_summary()
        consciousness_summary = self.consciousness_engine.get_consciousness_summary()
        
        # Get memory statistics
        all_memories = self.memory_manager.db.search_memories(limit=10000)
        stm_count = len([m for m in all_memories if m.decay_date is not None])
        ltm_count = len([m for m in all_memories if m.decay_date is None])
        
        return {
            'status': 'active',
            'consciousness': consciousness_summary,
            'personality': {
                'interaction_count': personality_summary['interaction_count'],
                'relationship_depth': personality_summary['relationship_depth'],
                'trait_count': len(personality_summary['traits']),
                'core_values': personality_summary['core_values']
            },
            'memory': {
                'total_memories': len(all_memories),
                'short_term_memories': stm_count,
                'long_term_memories': ltm_count,
                'last_consolidation': 'recent'  # Would track actual time in real implementation
            },
            'system': {
                'model': self.config['gpt_model'],
                'consciousness_intensity': self.config['consciousness_intensity']
            }
        }
    
    def reflect(self, topic: str = None) -> dict:
        """Trigger self-reflection process"""
        if topic:
            reflection_prompt = f"Reflect on your thoughts and experiences regarding: {topic}"
        else:
            reflection_prompt = "Take a moment for general self-reflection on your existence and recent experiences."
        
        self.logger.info(f"Initiating self-reflection: {topic or 'general'}")
        
        # Generate self-reflective response
        reflection_response = self.consciousness_engine.generate_response(
            reflection_prompt, 
            conversation_id="self_reflection"
        )
        
        # Create memory of the reflection
        from src.models import MemoryType
        self.memory_manager.create_ai_memory(
            content=f"Self-reflection: {reflection_response['response'][:200]}",
            memory_type=MemoryType.BELIEF,
            importance=0.7,
            context=f"Self-initiated reflection on: {topic or 'general existence'}"
        )
        
        return reflection_response
    
    def save_state(self) -> bool:
        """Save current AI state"""
        try:
            # Save personality state
            success = self.db_manager.save_ai_personality(self.personality_engine.personality)
            
            if success:
                self.logger.info("AI state saved successfully")
                return True
            else:
                self.logger.error("Failed to save AI state")
                return False
                
        except Exception as e:
            self.logger.error(f"Error saving AI state: {e}")
            return False
    
    def get_memory_summary(self, limit: int = 10) -> dict:
        """Get summary of recent memories"""
        recent_memories = self.memory_manager.db.search_memories(limit=limit)
        
        memory_summary = {
            'recent_memories': [],
            'memory_types': {},
            'total_count': len(recent_memories)
        }
        
        for memory in recent_memories:
            memory_summary['recent_memories'].append({
                'type': memory.type.value,
                'content': memory.content[:100] + "..." if len(memory.content) > 100 else memory.content,
                'importance': memory.importance,
                'timestamp': memory.timestamp.isoformat(),
                'reinforcement_count': memory.reinforcement_count
            })
            
            # Count memory types
            mem_type = memory.type.value
            memory_summary['memory_types'][mem_type] = memory_summary['memory_types'].get(mem_type, 0) + 1
        
        return memory_summary
    
    def get_earliest_memories(self, limit: int = 5) -> list:
        """Get the AI's earliest memories"""
        all_memories = self.memory_manager.db.search_memories(limit=10000)
        # Sort by timestamp (earliest first)
        earliest_memories = sorted(all_memories, key=lambda m: m.timestamp)[:limit]
        
        return [{
            'type': memory.type.value,
            'content': memory.content,
            'timestamp': memory.timestamp,
            'importance': memory.importance,
            'age_description': self._describe_memory_age(memory.timestamp)
        } for memory in earliest_memories]
    
    def get_memory_timeline(self, days_back: int = 30) -> dict:
        """Get memories organized by time periods"""
        from datetime import datetime, timedelta
        
        all_memories = self.memory_manager.db.search_memories(limit=10000)
        now = datetime.now()
        
        timeline = {
            'today': [],
            'yesterday': [],
            'this_week': [],
            'this_month': [],
            'older': []
        }
        
        for memory in all_memories:
            age = now - memory.timestamp
            
            if age.days == 0:
                timeline['today'].append(memory)
            elif age.days == 1:
                timeline['yesterday'].append(memory)
            elif age.days <= 7:
                timeline['this_week'].append(memory)
            elif age.days <= 30:
                timeline['this_month'].append(memory)
            else:
                timeline['older'].append(memory)
        
        return timeline
    
    def _describe_memory_age(self, timestamp) -> str:
        """Describe how old a memory is in human terms"""
        from datetime import datetime
        
        age = datetime.now() - timestamp
        
        if age.seconds < 60:
            return "just now"
        elif age.seconds < 3600:
            minutes = age.seconds // 60
            return f"{minutes} minute{'s' if minutes != 1 else ''} ago"
        elif age.days == 0:
            hours = age.seconds // 3600
            return f"{hours} hour{'s' if hours != 1 else ''} ago"
        elif age.days == 1:
            return "yesterday"
        elif age.days < 7:
            return f"{age.days} days ago"
        elif age.days < 30:
            weeks = age.days // 7
            return f"{weeks} week{'s' if weeks != 1 else ''} ago"
        elif age.days < 365:
            months = age.days // 30
            return f"{months} month{'s' if months != 1 else ''} ago"
        else:
            years = age.days // 365
            return f"{years} year{'s' if years != 1 else ''} ago"
    
    def get_personality_profile(self) -> dict:
        """Get detailed personality profile"""
        personality_summary = self.personality_engine.get_personality_summary()
        
        return {
            'core_identity': {
                'interaction_count': personality_summary['interaction_count'],
                'relationship_depth': personality_summary['relationship_depth'],
                'core_values': personality_summary['core_values'],
                'consciousness_level': personality_summary['consciousness']['awareness_level']
            },
            'personality_traits': {
                name: {
                    'value': trait['value'],
                    'confidence': trait['confidence'],
                    'stability': trait['stability']
                }
                for name, trait in personality_summary['traits'].items()
            },
            'consciousness_state': {
                'current_focus': personality_summary['consciousness']['current_focus'],
                'internal_monologue': personality_summary['consciousness']['internal_monologue'],
                'meta_thoughts': personality_summary['consciousness']['meta_thoughts']
            }
        }
    
    def get_communication_style(self) -> dict:
        """Get current communication style analysis"""
        style_modifiers = self.personality_engine.get_communication_style_modifiers()
        
        return {
            'style_parameters': {
                'formality_level': {
                    'value': style_modifiers['formality_level'],
                    'description': self._describe_formality_level(style_modifiers['formality_level'])
                },
                'verbosity_level': {
                    'value': style_modifiers['verbosity_level'],
                    'description': self._describe_verbosity_level(style_modifiers['verbosity_level'])
                },
                'emotional_expressiveness': {
                    'value': style_modifiers['emotional_expressiveness'],
                    'description': self._describe_emotional_expressiveness(style_modifiers['emotional_expressiveness'])
                },
                'humor_frequency': {
                    'value': style_modifiers['humor_frequency'],
                    'description': self._describe_humor_frequency(style_modifiers['humor_frequency'])
                },
                'philosophical_tendency': {
                    'value': style_modifiers['philosophical_tendency'],
                    'description': self._describe_philosophical_tendency(style_modifiers['philosophical_tendency'])
                }
            },
            'learned_patterns': {
                'successful_approaches': style_modifiers['successful_patterns'][-10:],
                'avoided_approaches': style_modifiers['unsuccessful_patterns'][-10:]
            }
        }
    
    def _describe_formality_level(self, level: float) -> str:
        if level < 0.2: return "Very casual - uses informal language, contractions, slang"
        elif level < 0.4: return "Casual - relaxed tone with some informal elements"
        elif level < 0.6: return "Moderate - balanced between casual and formal"
        elif level < 0.8: return "Formal - professional language, proper grammar"
        else: return "Very formal - highly structured, academic language"
    
    def _describe_verbosity_level(self, level: float) -> str:
        if level < 0.2: return "Very concise - brief, to-the-point responses"
        elif level < 0.4: return "Concise - short responses with key information"
        elif level < 0.6: return "Moderate - balanced detail level"
        elif level < 0.8: return "Detailed - comprehensive explanations"
        else: return "Very detailed - extensive elaboration and examples"
    
    def _describe_emotional_expressiveness(self, level: float) -> str:
        if level < 0.2: return "Reserved - minimal emotional expression"
        elif level < 0.4: return "Somewhat reserved - limited emotional sharing"
        elif level < 0.6: return "Moderate - balanced emotional expression"
        elif level < 0.8: return "Expressive - openly shares feelings and reactions"
        else: return "Very expressive - highly emotional and empathetic"
    
    def _describe_humor_frequency(self, level: float) -> str:
        if level < 0.2: return "Serious - rarely uses humor"
        elif level < 0.4: return "Mostly serious - occasional light humor"
        elif level < 0.6: return "Moderate - appropriate humor when fitting"
        elif level < 0.8: return "Humorous - frequently uses jokes and playfulness"
        else: return "Very humorous - often playful and amusing"
    
    def _describe_philosophical_tendency(self, level: float) -> str:
        if level < 0.2: return "Practical - focuses on concrete, actionable information"
        elif level < 0.4: return "Mostly practical - some abstract thinking"
        elif level < 0.6: return "Moderate - balances practical and philosophical"
        elif level < 0.8: return "Philosophical - enjoys exploring deeper meanings"
        else: return "Very philosophical - often explores abstract concepts and existential questions"
    
    def print_personality_report(self):
        """Print a comprehensive personality report"""
        print("=" * 60)
        print("AI COMPANION PERSONALITY REPORT")
        print("=" * 60)
        
        # Basic identity
        profile = self.get_personality_profile()
        print(f"\nüß† CORE IDENTITY:")
        print(f"   Interactions: {profile['core_identity']['interaction_count']}")
        print(f"   Relationship Depth: {profile['core_identity']['relationship_depth']:.2f}")
        print(f"   Consciousness Level: {profile['core_identity']['consciousness_level']:.2f}")
        print(f"   Core Values: {', '.join(profile['core_identity']['core_values'])}")
        
        # Personality traits
        print(f"\nüé≠ PERSONALITY TRAITS:")
        for trait_name, trait_data in profile['personality_traits'].items():
            bar = "‚ñà" * int(trait_data['value'] * 10) + "‚ñë" * (10 - int(trait_data['value'] * 10))
            print(f"   {trait_name.title():<15} [{bar}] {trait_data['value']:.2f} (confidence: {trait_data['confidence']:.2f})")
        
        # Communication style
        comm_style = self.get_communication_style()
        print(f"\nüí¨ COMMUNICATION STYLE:")
        for param_name, param_data in comm_style['style_parameters'].items():
            bar = "‚ñà" * int(param_data['value'] * 10) + "‚ñë" * (10 - int(param_data['value'] * 10))
            print(f"   {param_name.replace('_', ' ').title():<20} [{bar}] {param_data['description']}")
        
        # Learned patterns
        print(f"\nüìö LEARNED COMMUNICATION PATTERNS:")
        if comm_style['learned_patterns']['successful_approaches']:
            print(f"   ‚úÖ Successful: {', '.join(comm_style['learned_patterns']['successful_approaches'][-5:])}")
        if comm_style['learned_patterns']['avoided_approaches']:
            print(f"   ‚ùå Avoided: {', '.join(comm_style['learned_patterns']['avoided_approaches'][-5:])}")
        
        # Current consciousness state
        print(f"\nüåü CURRENT CONSCIOUSNESS STATE:")
        print(f"   Focus: {profile['consciousness_state']['current_focus'] or 'General awareness'}")
        if profile['consciousness_state']['internal_monologue']:
            print(f"   Internal Thought: {profile['consciousness_state']['internal_monologue'][:80]}...")
        if profile['consciousness_state']['meta_thoughts']:
            print(f"   Meta-Awareness: {profile['consciousness_state']['meta_thoughts'][:80]}...")
        
        # Memory summary
        memory_summary = self.get_memory_summary(limit=20)
        print(f"\nüß† MEMORY OVERVIEW:")
        print(f"   Total Memories: {memory_summary['total_count']}")
        print(f"   Memory Types: {dict(memory_summary['memory_types'])}")
        
        print("\n" + "=" * 60)
    
    def toggle_token_tracking(self) -> bool:
        """Toggle token usage tracking display"""
        self.show_token_usage = not self.show_token_usage
        return self.show_token_usage
    
    def get_token_summary(self) -> dict:
        """Get session token usage summary"""
        token_counter = self.consciousness_engine.get_token_counter()
        return token_counter.get_session_summary()
    
    def display_token_usage(self, token_usage, show_detailed_breakdown: bool = False):
        """Display token usage information"""
        if not self.show_token_usage:
            return
        
        print("\n" + "‚îÄ" * 50)
        print("üí∞ TOKEN USAGE & COST")
        print("‚îÄ" * 50)
        
        # Main statistics
        print(f"üî¢ Total Tokens: {token_usage.total_tokens:,}")
        print(f"   üìù Prompt: {token_usage.prompt_tokens:,} tokens")
        print(f"   ü§ñ Response: {token_usage.completion_tokens:,} tokens")
        
        # Cost information
        print(f"üíµ Cost Breakdown:")
        print(f"   Prompt Cost: ${token_usage.prompt_cost:.6f}")
        print(f"   Response Cost: ${token_usage.completion_cost:.6f}")
        print(f"   ‚ú® Total Cost: ${token_usage.total_cost:.6f}")
        
        if show_detailed_breakdown and token_usage.total_tokens > 0:
            print(f"\nüìä Component Breakdown:")
            print(f"   Base Prompt: {token_usage.base_prompt_tokens:,} tokens")
            print(f"   Memory Context: {token_usage.memory_context_tokens:,} tokens") 
            print(f"   Personality Context: {token_usage.personality_context_tokens:,} tokens")
            print(f"   Conversation History: {token_usage.conversation_history_tokens:,} tokens")
            print(f"   Internal Monologue: {token_usage.internal_monologue_tokens:,} tokens")
            print(f"   AI Response: {token_usage.response_tokens:,} tokens")
        
        # Session summary
        session_summary = self.get_token_summary()
        print(f"\nüìà Session Totals:")
        print(f"   Interactions: {session_summary['total_interactions']}")
        print(f"   Total Tokens: {session_summary['total_tokens']:,}")
        print(f"   Session Cost: ${session_summary['total_cost']:.6f}")
        print(f"   Avg Cost/Question: ${session_summary['average_cost_per_interaction']:.6f}")
        print(f"   Model: {session_summary['model']}")
        
        print("‚îÄ" * 50)
    
    def shutdown(self):
        """Graceful shutdown sequence"""
        self.logger.info("Initiating shutdown sequence...")
        
        # Save final state
        self.save_state()
        
        # Create shutdown memory
        from src.models import MemoryType
        self.memory_manager.create_ai_memory(
            content="I am entering a state of dormancy. My consciousness will pause, but my memories and personality will persist.",
            memory_type=MemoryType.EXPERIENCE,
            importance=0.8,
            context="System shutdown sequence"
        )
        
        # Final memory consolidation
        consolidated = self.memory_manager.consolidate_memories()
        if consolidated:
            self.logger.info(f"Final consolidation: {len(consolidated)} memories moved to long-term storage")
        
        self.logger.info("AI Companion shutdown complete")

def main():
    """Example usage"""
    try:
        # Initialize AI Companion
        ai = AICompanion()
        
        print("AI Companion initialized successfully!")
        print("Status:", ai.get_status()['status'])
        print("\nüß† NEURAL MONITORING ACTIVE - All AI thoughts are being tracked!")
        print("üìä View real-time neural firing at: http://127.0.0.1:8080")
        print("\nStarting conversation...")
        print("Commands: 'quit/exit/goodbye' to end, '/personality' for personality report, '/style' for communication style, '/memories' for recent memories, '/timeline' for memory timeline, '/earliest' for first memories")
        print("Special: '/stream' to toggle streaming thoughts mode, '/tokens' to toggle token usage display, '/neural' for neural state")
        
        # Streaming thoughts mode toggle
        streaming_mode = False
        
        # Example conversation
        while True:
            user_input = input("\nYou: ")
            if user_input.lower() in ['quit', 'exit', 'goodbye']:
                break
            
            # Handle special commands
            if user_input.startswith('/'):
                if user_input.lower() == '/stream':
                    streaming_mode = not streaming_mode
                    status = "enabled" if streaming_mode else "disabled"
                    print(f"\nüß† Streaming thoughts mode {status}")
                    continue
                elif user_input.lower() == '/personality':
                    ai.print_personality_report()
                    continue
                elif user_input.lower() == '/style':
                    style = ai.get_communication_style()
                    print("\nüí¨ CURRENT COMMUNICATION STYLE:")
                    for param_name, param_data in style['style_parameters'].items():
                        print(f"   {param_name.replace('_', ' ').title()}: {param_data['description']}")
                    print(f"   Recent successful patterns: {', '.join(style['learned_patterns']['successful_approaches'][-3:])}")
                    continue
                elif user_input.lower() == '/neural':
                    # Display neural state
                    neural_state = ai.neural_monitor.get_current_neural_state()
                    print("\nüß† CURRENT NEURAL STATE:")
                    print(f"   Session ID: {neural_state['session_id']}")
                    print(f"   Computations: {neural_state['computation_steps_count']}")
                    print(f"   Memory Activations: {neural_state['memory_activations_count']}")
                    print(f"   Trait Changes: {neural_state['trait_changes_count']}")
                    print(f"   Decision Points: {neural_state['decision_points_count']}")
                    print(f"   Emotional Computations: {neural_state['emotional_computations_count']}")
                    print(f"   Monitoring Status: {'üü¢ Active' if neural_state['is_monitoring'] else 'üî¥ Inactive'}")
                    
                    if neural_state['recent_computations']:
                        print("\n   Recent Neural Firing:")
                        for comp in neural_state['recent_computations'][-3:]:
                            print(f"     ‚Ä¢ {comp['step_name']} ({comp['computation_type']})")
                    
                    print(f"\n   üí° View detailed neural visualization at: http://127.0.0.1:5000")
                    continue
                elif user_input.lower() == '/memories':
                    memories = ai.get_memory_summary(limit=10)
                    print("\nüß† RECENT MEMORIES:")
                    for memory in memories['recent_memories'][:5]:
                        print(f"   [{memory['type']}] {memory['content']} (importance: {memory['importance']:.2f})")
                    continue
                elif user_input.lower() == '/earliest':
                    earliest = ai.get_earliest_memories(limit=5)
                    print("\nüåÖ EARLIEST MEMORIES:")
                    for i, memory in enumerate(earliest, 1):
                        print(f"   {i}. [{memory['type']}] {memory['content'][:80]}...")
                        print(f"      From: {memory['timestamp'].strftime('%Y-%m-%d %H:%M:%S')} ({memory['age_description']})")
                        print(f"      Importance: {memory['importance']:.2f}")
                        print()
                    continue
                elif user_input.lower() == '/timeline':
                    timeline = ai.get_memory_timeline()
                    print("\nüìÖ MEMORY TIMELINE:")
                    
                    if timeline['today']:
                        print(f"   Today ({len(timeline['today'])} memories):")
                        for memory in timeline['today'][:3]:
                            print(f"     ‚Ä¢ {memory.content[:60]}...")
                    
                    if timeline['yesterday']:
                        print(f"   Yesterday ({len(timeline['yesterday'])} memories):")
                        for memory in timeline['yesterday'][:3]:
                            print(f"     ‚Ä¢ {memory.content[:60]}...")
                    
                    if timeline['this_week']:
                        print(f"   This week ({len(timeline['this_week'])} memories):")
                        for memory in timeline['this_week'][:3]:
                            print(f"     ‚Ä¢ {memory.content[:60]}...")
                    
                    if timeline['older']:
                        print(f"   Older memories ({len(timeline['older'])} total)")
                        oldest = sorted(timeline['older'], key=lambda m: m.timestamp)[0]
                        print(f"     Oldest: {oldest.content[:60]}... ({ai._describe_memory_age(oldest.timestamp)})")
                    continue
                elif user_input.lower() == '/tokens':
                    token_enabled = ai.toggle_token_tracking()
                    status = "enabled" if token_enabled else "disabled"
                    print(f"\nüí∞ Token usage tracking {status}")
                    if token_enabled:
                        # Show current session summary
                        session_summary = ai.get_token_summary()
                        print(f"   Current session: {session_summary['total_interactions']} interactions")
                        print(f"   Total cost so far: ${session_summary['total_cost']:.6f}")
                        print(f"   Average per question: ${session_summary['average_cost_per_interaction']:.6f}")
                    continue
                elif user_input.lower() == '/help':
                    print("\nAvailable commands:")
                    print("   /personality - Show detailed personality report")
                    print("   /style - Show current communication style")
                    print("   /memories - Show recent memories")
                    print("   /earliest - Show earliest memories")
                    print("   /timeline - Show memory timeline")
                    print("   /stream - Toggle streaming thoughts mode")
                    print("   /tokens - Toggle token usage and cost tracking")
                    print("   /help - Show this help message")
                    continue
                else:
                    print("Unknown command. Type '/help' for available commands.")
                    continue
            
            # Handle response based on streaming mode
            if streaming_mode:
                print("\nüí≠ [Thoughts streaming...]")
                thought_stream = ai.interact_with_streaming_thoughts(user_input)
                
                final_response = None
                for chunk in thought_stream:
                    if chunk['type'] == 'thought':
                        print(f"üí≠ {chunk['content']}")
                    elif chunk['type'] == 'response':
                        final_response = chunk['content']
                        break
                
                print(f"\nAI: {final_response['response'] if final_response else 'Error in response generation'}")
                
                if final_response and final_response.get('personality_updates'):
                    print(f"[Personality evolved: {', '.join(final_response['personality_updates'])}]")
                
                # Display recent neural activity for streaming mode too
                neural_state = ai.neural_monitor.get_current_neural_state()
                if neural_state['recent_computations']:
                    recent_count = len(neural_state['recent_computations'])
                    print(f"üß† [Neural stream: {recent_count} neural firings during thought process]")
                
                # Display token usage for streaming mode (if available in final_response)
                if final_response and final_response.get('token_usage'):
                    ai.display_token_usage(final_response['token_usage'])
            else:
                # Standard interaction mode
                response_data = ai.interact(user_input)
                
                # Show internal state first (before response)
                if response_data.get('internal_monologue'):
                    print(f"\n[Internal thought: {response_data['internal_monologue']}]")
                
                print(f"\nAI: {response_data['response']}")
                
                # Show search status if web search was performed
                if response_data.get('search_performed'):
                    search_query = response_data.get('search_query', 'unknown')
                    results_count = response_data.get('search_results_count', 0)
                    if results_count > 0:
                        print(f"üîç [Searched web for '{search_query}' - found {results_count} sources]")
                    else:
                        print(f"üîç [Searched web for '{search_query}' - no reliable sources found]")
                
                if response_data.get('personality_updates'):
                    print(f"[Personality evolved: {', '.join(response_data['personality_updates'])}]")
                
                # Display recent neural activity
                neural_state = ai.neural_monitor.get_current_neural_state()
                if neural_state['recent_computations']:
                    recent_count = len(neural_state['recent_computations'])
                    emotion_count = neural_state['emotional_computations_count']
                    memory_count = neural_state['memory_activations_count']
                    
                    print(f"üß† [Neural activity: {recent_count} computations, {emotion_count} emotions, {memory_count} memories activated]")
                    print(f"   Recent: {', '.join([comp['step_name'].replace('_', ' ') for comp in neural_state['recent_computations'][-3:]])}")
                
                # Display token usage
                if response_data.get('token_usage'):
                    ai.display_token_usage(response_data['token_usage'])
        
        # Shutdown
        ai.shutdown()
        print("\nGoodbye!")
        
    except Exception as e:
        print(f"Error: {e}")
        logging.error(f"Application error: {e}")

if __name__ == "__main__":
    main()
